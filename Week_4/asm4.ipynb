{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0011c05",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db8f4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from torch import Tensor\n",
    "from numpy import ndarray\n",
    "from typing import Type\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba31b9ef",
   "metadata": {},
   "source": [
    "# Import Data and Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f583f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(\"./data/O-A0038-003.xml\")\n",
    "root = tree.getroot()\n",
    "ns = {\"ns\": \"urn:cwa:gov:tw:cwacommon:0.1\"}\n",
    "\n",
    "# long_min, long_max, lat_min, lat_max\n",
    "llrange = [\n",
    "    float(root.find(\"./ns:dataset/ns:GeoInfo/ns:{0}\".format(tag), ns).text)\n",
    "    for tag in [\n",
    "        \"BottomLeftLongitude\",\n",
    "        \"TopRightLongitude\",\n",
    "        \"BottomLeftLatitude\",\n",
    "        \"TopRightLatitude\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# template data\n",
    "data = np.array([\n",
    "    [float(temp) for temp in row.split(',')]\n",
    "    for row in root.find(\"./ns:dataset/ns:Resource/ns:Content\", ns).text.split('\\n')\n",
    "])\n",
    "\n",
    "# long & lat grid\n",
    "long_grid, lat_grid = np.mgrid[llrange[1]:llrange[0]:120j, llrange[2]:llrange[3]:67j]\n",
    "\n",
    "# Classification dataset (long, lat, label)\n",
    "classData = np.array([\n",
    "    [long_grid[i, j], lat_grid[i, j], 0 if data[i, j] == -999 else 1]\n",
    "    for i in range(120)\n",
    "    for j in range(67)\n",
    "])\n",
    "\n",
    "# Regression dataset (long, lat, value)\n",
    "regData = np.array([\n",
    "    [long_grid[i, j], lat_grid[i, j], data[i, j]]\n",
    "    for i in range(120)\n",
    "    for j in range(67)\n",
    "    if data[i, j] != -999\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df46359",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bb6b5b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvt_split(arr: ndarray) -> tuple:\n",
    "    idx   = np.random.permutation(len(arr))\n",
    "    n     = int(0.1*len(arr))\n",
    "    train = arr[idx[2*n:]]\n",
    "    valid = arr[idx[:n]]\n",
    "    test  = arr[idx[n:2*n]]\n",
    "    return train, valid, test\n",
    "\n",
    "def toTensor(arr: ndarray) -> Tensor:\n",
    "    return torch.tensor(arr, dtype=torch.float32)\n",
    "\n",
    "class BasicDataSet:\n",
    "    def __init__(self, _data: ndarray) -> None:\n",
    "        self.data : ndarray = _data\n",
    "        self.X    : ndarray = self.data[:, :2]\n",
    "        self.X_t  : Tensor  = toTensor(self.X)\n",
    "\n",
    "class NormalDataSet(BasicDataSet):\n",
    "    def __init__(self, _data: ndarray) -> None:\n",
    "        super(NormalDataSet, self).__init__(_data)\n",
    "        self.Y  : ndarray = self.data[:, 2:]\n",
    "        self.Y_t: Tensor  = toTensor(self.Y)\n",
    "\n",
    "class OneHotDataSet(BasicDataSet):\n",
    "    def __init__(self, _data: ndarray) -> None:\n",
    "        super(OneHotDataSet, self).__init__(_data)\n",
    "        self.Y  : ndarray = np.array([[1, 0] if row[2] == 0 else [0, 1] for row in self.data])\n",
    "        self.Y_t: Tensor  = toTensor(self.Y)\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self, _data: ndarray, _bds: Type[BasicDataSet]) -> None:\n",
    "        self.data : ndarray = _data\n",
    "        self.train: Type[BasicDataSet]\n",
    "        self.valid: Type[BasicDataSet]\n",
    "        self.test : Type[BasicDataSet]\n",
    "        self.train, self.valid, self.test = tuple(_bds(splitdata) for splitdata in tvt_split(_data))\n",
    "\n",
    "classDS = DataSet(classData, NormalDataSet)\n",
    "regDS   = DataSet(regData  , NormalDataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc6963",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b0567869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(ClassModel, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(2, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.seq(X)\n",
    "\n",
    "class RegModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(RegModel, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(2, 10),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.seq(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c673e",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7a7ee389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingFunc(net, criterion, optimizer, trainEpoch: int, DS: DataSet) -> tuple:\n",
    "    trainlosslist = []\n",
    "    validlosslist = []\n",
    "\n",
    "    print(\" Epoch | trainLoss | validLoss \")\n",
    "    print(\"-------|-----------|-----------\")\n",
    "\n",
    "    for epoch in range(trainEpoch):\n",
    "        # train data\n",
    "        optimizer.zero_grad()\n",
    "        y_train = net(DS.train.X_t)\n",
    "        trainloss = criterion(y_train, DS.train.Y_t)\n",
    "        trainloss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # valid data\n",
    "        y_valid = net(DS.valid.X_t)\n",
    "        validloss = criterion(y_valid, DS.valid.Y_t)\n",
    "\n",
    "        # record\n",
    "        trainlosslist.append(trainloss.item())\n",
    "        validlosslist.append(validloss.item())\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(\" {0:5d} | {1:9.6f} | {2:9.6f} \".format(epoch, trainloss.item(), validloss.item()))\n",
    "    \n",
    "    return trainlosslist, validlosslist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a2ef8f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "55cfa209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch | trainLoss | validLoss \n",
      "-------|-----------|-----------\n",
      "     0 |  7.602461 |  6.650561 \n",
      "   100 |  0.686394 |  0.671436 \n",
      "   200 |  0.686363 |  0.670692 \n",
      "   300 |  0.686356 |  0.670699 \n",
      "   400 |  0.686349 |  0.670699 \n",
      "   500 |  0.686340 |  0.670699 \n",
      "   600 |  0.686331 |  0.670700 \n",
      "   700 |  0.686323 |  0.670702 \n",
      "   800 |  0.686314 |  0.670704 \n",
      "   900 |  0.686306 |  0.670707 \n"
     ]
    }
   ],
   "source": [
    "net        = ClassModel()\n",
    "criterion  = nn.BCELoss()\n",
    "optimizer  = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "trainEpoch = 1000\n",
    "\n",
    "trainlosslist, validlosslist = trainingFunc(net, criterion, optimizer, trainEpoch, classDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "590535ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tmp.txt\", 'w') as file:\n",
    "    for i in range(120):\n",
    "        for j in range(67):\n",
    "            y = net(toTensor([long_grid[i, j], lat_grid[i, j]]))\n",
    "            file.write('000' if y[0] < 0.5 else '111')\n",
    "        file.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
