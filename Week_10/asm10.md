# Week 10 Assignment


## Problem 1

> Consider a forward SDE
>
> $$
> dx_t = f(x_t, t)dt + g(x_t, t)dW_t,
> $$
>
> show that the corresponding probability flow ODE is written as
>
> $$
> dx_t = \left[f(x_t,t) -\frac{1}{2}\frac{\partial}{\partial x}g^2(x_t, t)- \frac{g^2(x_t,t)}{2}\frac{\partial}{\partial x}\log p(x_t,t)\right]dt.
> $$

### 目標

我們希望找到一個確定性飄移 $F(x, t)$ ，使得ODE

$$
dx_t = F(x, t) dt
$$

所產生的概率密度演化 $\frac{\partial p}{\partial t}$ 和SDE

$$
dx_t = f(x_t, t)dt + g(x_t, t)dW_t
$$

產生的概率密度演化相同

接下來的推導中，記 $p = p(x, t)$ , $f = f(x, t)$ , $g = g(x, t)$

### 第一步：SDE 的 Fokker-Planck 方程

對於一個SDE

$$
dx_t = f(x_t, t)dt + g(x_t, t)dW_t
$$

它的Fokker-Planck方程為

$$
\frac{\partial p}{\partial t} = -\frac{\partial}{\partial x}(fp) + \frac{1}{2}\frac{\partial^2}{\partial x^2}(g^2 p)
$$

### 第二步：ODE 的连续性方程

對於ODE

$$
dx_t = F(x, t) dt
$$

假設其概率密度也為 $p$ ，那 $p$ 必須滿足連續性方程

$$
\frac{\partial p}{\partial t} + \frac{\partial}{\partial x} (p F) = 0
$$

### 第三步：求解 $F$

聯立一，二步中的兩個方程：

$$
-\frac{\partial}{\partial x} (F p) = -\frac{\partial}{\partial x} (f p) + \frac{1}{2} \frac{\partial^2}{\partial x^2} (g^2 p)
$$

兩邊同時對 $x$ 積分（假設積分常數為0）

$$
-(F p) = - (f p) + \frac{1}{2} \frac{\partial}{\partial x} (g^2 p)
$$

計算得

$$
\begin{align*}
F
&= f - \frac{1}{2p} \frac{\partial}{\partial x} (g^2 p) \\
&= f - \frac{1}{2p} \left[ \left( \frac{\partial g^2}{\partial x} \right) p + g^2 \left( \frac{\partial p}{\partial x} \right) \right] \\
&= f - \frac{1}{2} \frac{\partial g^2}{\partial x} - \frac{g^2}{2} \left( \frac{1}{p} \frac{\partial p}{\partial x} \right) \\
&= f - \frac{1}{2} \frac{\partial g^2}{\partial x} - \frac{g^2}{2} \frac{\partial}{\partial x} \log p
\end{align*}
$$

因此，

$$
dx_t = \left[f(x_t,t) -\frac{1}{2}\frac{\partial}{\partial x}g^2(x_t, t)- \frac{g^2(x_t,t)}{2}\frac{\partial}{\partial x}\log p(x_t,t)\right]dt
$$


## Problem 2

> AI 的未來與機器學習的基石

### AI 與音樂創作：從模仿到共鳴

在未來二十年，AI 可能具備一項具有深遠意義的能力：**創作能與人類情感共鳴的音樂**。這種 AI 不僅能模仿旋律風格或節奏結構，而是能真正理解人類的情緒、文化脈絡與創作意圖，進而與聽眾產生情感上的交流。這將標誌著 AI 從「創作工具」走向「藝術主體」的轉變。

目前的生成式音樂系統（如 OpenAI 的 MuseNet 或 Google 的 MusicLM）已能生成風格多樣、技術上完整的樂曲，但多數作品仍缺乏「情感厚度」——它們像是在模仿一種形式，而非表達一種情感。真正具共鳴的音樂不僅依賴音符，更源自創作者的情感經驗與文化背景。未來的 AI 若能理解人類的情緒結構與文化語意，便有可能創作出讓人動容的旋律。

這樣的 AI 在應用上將徹底改變音樂產業與教育。對創作者而言，它能成為靈感的夥伴，根據音樂家的情緒狀態與創作方向，主動生成和弦走向、旋律草稿或配器建議；對一般聽眾而言，它能即時生成符合當下心境的音樂，甚至根據腦波、語音或面部表情自動調整音樂氛圍。例如，在治療與心理輔導中，AI 音樂系統能生成專屬的「情緒調節音景」，幫助使用者放鬆或重新聚焦。

### 涉及的機器學習類型

要實現這種具「共鳴」能力的 AI，將結合**非監督式學習**與**強化學習**：

- **非監督式學習**：AI 從大量音樂資料中學習音樂結構、節奏、風格與文化模式，形成對不同音樂語彙的內在表徵；

- **強化學習**：透過與人類互動，根據使用者的情緒反饋（如滿意度、專注度或情感評分）不斷調整生成策略，使音樂逐步更貼近人類情感需求。

在這裡，資料來源包括歷史樂譜、錄音檔案與情緒標註資料，而「目標訊號」則是人類對音樂的主觀反應。AI 將學習如何從「音符的組合」推測出「情感的意圖」，這正是模仿與共鳴的分水嶺。

### 第一個研究步驟：簡化模型問題

當然，在 AI 創作出這些飽含情感的音樂之前，還有一件更重要的事，那就是音樂要好聽。所以我認為簡化模型的第一步應該是———**音樂評分模型**，AI 自己得先是一個符合人類品味的音樂聽眾吧。

- **與理想模型的聯繫：** \
  先讓 AI 產生自己的音樂審美，再以自己的審美為標準去創作音樂，而不是單純的去模仿，「臨摹」人類的音樂作品。為之後對於情感屬性的理解和創作打下基礎。
- **可測試性：** \
  成功與否可透過對比 AI 和人類對於相同音樂的評價來衡量。
- **需要的數學或機器學習工具：** \
  人類對於音樂的感覺很微妙，背後的數學原理或許十分複雜，我們可以嘗試以下幾個方案，試錯並找出一個合適的路線：
    - 回歸模型方案： \
      準備一組訓練數據 -（樂譜，評分） \
      訓練一個回歸模型，學習樂譜和評分之間的函數關係
    - CNN方案： \
      與回歸方案類似，但我們多加上卷積層，或許會有奇效？
    - LLM方案： \
      把樂譜想象成句子，那生成一段樂譜不就是大語言模型在做的事嗎？每次生成一個音符之前，去分析前面已生成的音符，推理出接下來「最有可能出現」的音符。當然這有點離題了，我們的主題只是一個評分模型，但如果接下來要做一個生成模型，這是有用的。
    - 擴散模型方案： \
      一樣，如果要做一個生成模型，我們可以採取擴散模型的思想，一開始給模型一段雜音，讓其學習去噪的過程（讓音樂變好聽的過程）。

使用不同的訓練數據，我們甚至可以訓練出一個「有偏見」的 AI，例如只餵它「憂鬱」「悲傷」的音樂，它就會成為一個emo仔，只聽華語苦情歌。這種可以針對特定情感甚至特定流派的音樂的評分模型，相信對我們 AI 音樂情感共鳴的目標是有幫助的。

### 結語

當 AI 從模仿風格走向理解情感，它將不只是音樂產業的輔助者，而是新的創作者與共鳴者。這樣的 AI 可能會讓我們重新思考「藝術」與「創造力」的意義：音樂不再僅屬於人類的靈感，而成為人與機器共同探索情感的橋樑。


## Problem 3

> Unanswered Questions

1. 在實際複雜系統（例如氣候或生物網路）中，使用機率流 ODE 作為降維或生成模型是否具有可擴展性？其計算與統計瓶頸在什麼規模開始變得不可行？
